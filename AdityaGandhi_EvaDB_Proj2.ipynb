{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLMVgZSRNpV-"
      },
      "source": [
        "# ChatGPT Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkxqJpOKNpV_"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/georgia-tech-db/eva/blob/master/tutorials/08-chatgpt.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run on Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/georgia-tech-db/eva/blob/master/tutorials/08-chatgpt.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/georgia-tech-db/eva/raw/master/tutorials/08-chatgpt.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /> Download notebook</a>\n",
        "  </td>\n",
        "</table><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk1bCxw7NpWA"
      },
      "source": [
        "### Connect to EvaDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uOlGsA2nNpWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73bf469-0a56-4218-d5cb-dfc71a1dcbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.7/578.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.6/111.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/sentencepiece/\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"http://ml.cs.tsinghua.edu.cn/~chenxi/pytorch-models/mnist-b07bb66b.pth\" to /root/.cache/torch/hub/checkpoints/mnist-b07bb66b.pth\n",
            "100%|██████████| 1.03M/1.03M [00:01<00:00, 855kB/s] \n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet \"evadb[document,notebook]\"\n",
        "import evadb\n",
        "cursor = evadb.connect().cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNTT0x5ONpWC"
      },
      "source": [
        "## Set your OpenAI API key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5GLCqo8yNpWC"
      },
      "outputs": [],
      "source": [
        "# Set your OpenAI key as an environment variable\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "open_ai_key = os.environ.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4llhnBlOz6i",
        "outputId": "b9f7818d-fca2-4cad-832f-6cfce8c51ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eva--decord\n",
            "  Downloading eva_decord-0.6.1-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from eva--decord) (1.23.5)\n",
            "Installing collected packages: eva--decord\n",
            "Successfully installed eva--decord-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install eva--decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhCZB84pqMBn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mopH0OCqL1o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specific version of OpenAI might be required, in that case run the below code.\n",
        "Restart the terminal for the changes to take effect"
      ],
      "metadata": {
        "id": "X-tJclUxqMNz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ArJBI-9BWPe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# WARNING:\n",
        "# OPENAI OR RATHER TIKTOKEN MODULEMIGHT NOT WORK WITH SOME OPENAI VERSIONS.\n",
        "# IN SUCH CASES, IT WOULD BE BETTER IF A SPECIFIC VERSION OF OPENAI - 0.27.0 IS DOWNLOADED\n",
        "# FOR THAT FIRST UNINSTALL THE CURRENT OPENAI VERSION, IF ANY PRESENT\n",
        "# THEN DO INSTALL THE SPECIFIC OPENAI VERSION\n",
        "# RESTART THE TERMINAL FOR THE CHANGES TO TAKE PLACE\n",
        "\n",
        "# !pip uninstall openai\n",
        "# !pip install openai==0.27.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb4EwEE_Xqsu",
        "outputId": "c68a6521-f900-43ff-8d6c-d2ca370b7485"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: openai 1.3.5\n",
            "Uninstalling openai-1.3.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/openai\n",
            "    /usr/local/lib/python3.10/dist-packages/openai-1.3.5.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/openai/*\n",
            "Proceed (Y/n)? Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 680, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 375, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 415, in _allowed_to_proceed\n",
            "    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 192, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting openai==0.27.0\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.0) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.0) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.0) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.0) (1.3.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3888, in parseImpl\n",
            "    resultlist += exprtokens\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 443, in __iadd__\n",
            "    if isinstance(v[0], ParseResults):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1734, in isEnabledFor\n",
            "    _acquireLock()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 226, in _acquireLock\n",
            "    _lock.acquire()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we install tiktoken - a module used for counting the tokens !"
      ],
      "metadata": {
        "id": "_2O2EYP4qCwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Gb-Ya72Xr0",
        "outputId": "c85341ef-d889-4a48-cf49-bf38c29d5b6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QSpMtAbqW5Ht"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GYh8mRo51vI_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_En1aqc8OlXO",
        "outputId": "00465c06-341f-457c-9663-65d30a5a6b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   f1_score  cost                                             output\n",
            "0  0.285714  0.74  Output - '{Location: [Japan, China], Organizat...\n"
          ]
        }
      ],
      "source": [
        "total_cost = 0\n",
        "cost_per_token = 0.000004\n",
        "\n",
        "\n",
        "df = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "def count_tokens(prompt):\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    num_tokens = len(encoding.encode(prompt))\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "def convert_dict_values_to_lower(dict_obj):\n",
        "  lower_dict = {}\n",
        "  for key, value in dict_obj.items():\n",
        "    if isinstance(value, str):\n",
        "      lower_dict[key] = value.lower()\n",
        "    elif isinstance(value, list):\n",
        "      lower_dict[key] = [item.lower() for item in value]\n",
        "    elif isinstance(value, dict):\n",
        "      lower_dict[key] = convert_dict_values_to_lower(value)\n",
        "    else:\n",
        "      lower_dict[key] = value\n",
        "  return lower_dict\n",
        "\n",
        "def convert_list_to_lower(list_obj):\n",
        "  lower_list = [item.lower() for item in list_obj]\n",
        "  return lower_list\n",
        "\n",
        "\n",
        "def process_batch(batch):\n",
        "  for i in batch.index:\n",
        "    processed_df = pd.DataFrame([{'example': batch['example'][i]}], columns=['example'])\n",
        "    curr_tokens = count_tokens(batch['example'][i])\n",
        "\n",
        "    # 138 tokens are in the prompt being passed.\n",
        "    total_tokens = curr_tokens + 138\n",
        "\n",
        "    # here, in order to match all words as per their category, we get them seprarately and convert all such words to lowercase\n",
        "    data_dict = json.loads(batch['tokens'][i])\n",
        "    data_dict = convert_dict_values_to_lower(data_dict)\n",
        "\n",
        "    # getting each given labelled category words in different arrays for comparison later\n",
        "    loc_words = data_dict[\"Location\"]\n",
        "    org_words = data_dict[\"Organization\"]\n",
        "    per_words = data_dict[\"Person\"]\n",
        "    mis_words = data_dict[\"Miscellaneous\"]\n",
        "\n",
        "    # Here, we append the current row to a csv file temporarily, so it can be later read by the Chat-gpt function and parsed as the current input\n",
        "    processed_df.to_csv('temp.csv', index=False, header=True)\n",
        "    temp_df = pd.read_csv('temp.csv')\n",
        "\n",
        "   # we like create a new table, and put the current row in it, from the csv file 'temp'\n",
        "    cursor.query(\"\"\"\n",
        "      DROP TABLE IF EXISTS Temporary;\n",
        "    \"\"\").df()\n",
        "\n",
        "    cursor.query(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS Temporary (\n",
        "            example TEXT(5000)\n",
        "        );\n",
        "    \"\"\").df()\n",
        "\n",
        "    cursor.query(\"LOAD CSV 'temp.csv' INTO Temporary\").df()\n",
        "\n",
        "    # Here, we pass the current row into chat-gpt with a prompt in order to extract all the required entities from it.\n",
        "    chatgpt_udf = \"\"\"\n",
        "        SELECT ChatGPT( \"prompt: 'You are an expert at extracting Person, Organization, Location, and Miscellaneous entities from text. Your job is to extract named entities mentioned in text, and classify them into one of the following categories:',\n",
        "            'labels': [\n",
        "                'Location',\n",
        "                'Organization',\n",
        "                'Person',\n",
        "                'Miscellaneous'\n",
        "            ],\n",
        "            For the given example,\n",
        "            Example input - 'The role of the 70,000 mainly Kurdish village guards who fight Kurdistan Workers Party ( PKK ) guerrillas in the southeast has been questioned recently after media allegations that many of them are involved in common crime .'\n",
        "            Output - '{Location: [], Organization: [Kurdistan Workers Party, PKK], Person: [], Miscellaneous: [Kurdish]}'\n",
        "        }\", example)\n",
        "        FROM Temporary;\n",
        "    \"\"\"\n",
        "    ans = cursor.query(chatgpt_udf).df()\n",
        "\n",
        "    # We also add the answer token in the total count, to compute what is the actual cost.\n",
        "    total_tokens += count_tokens(ans['response'][0])\n",
        "    curr_cost = total_tokens * cost_per_token\n",
        "\n",
        "\n",
        "    # Now, the answer is in a string format, we try to separate each word as per the category for comparison\n",
        "    pattern1 = r'Location: \\[(.*?)\\]'\n",
        "    match1 = re.search(pattern1, ans['response'][0])\n",
        "    if match1:\n",
        "        output1 = match1.group(1).split(', ')\n",
        "        location_words = [element.strip('\"') for element in output1]\n",
        "    else:\n",
        "        location_words = []\n",
        "\n",
        "    pattern2 = r'Organization: \\[(.*?)\\]'\n",
        "    match2 = re.search(pattern2, ans['response'][0])\n",
        "    if match2:\n",
        "        output2 = match2.group(1).split(', ')\n",
        "        organization_words = [element.strip('\"') for element in output2]\n",
        "    else:\n",
        "        organization_words = []\n",
        "\n",
        "    pattern3 = r'Person: \\[(.*?)\\]'\n",
        "    match3 = re.search(pattern3, ans['response'][0])\n",
        "    if match3:\n",
        "        output3 = match3.group(1).split(', ')\n",
        "        person_words = [element.strip('\"') for element in output3]\n",
        "    else:\n",
        "        person_words = []\n",
        "\n",
        "    pattern4 = r'Miscellaneous: \\[(.*?)\\]'\n",
        "    match4 = re.search(pattern4, ans['response'][0])\n",
        "    if match4:\n",
        "        output4 = match4.group(1).split(', ')\n",
        "        misc_words = [element.strip('\"') for element in output4]\n",
        "    else:\n",
        "        misc_words = []\n",
        "\n",
        "    # We convert each word to lower-case\n",
        "    location_words = convert_list_to_lower(location_words)\n",
        "    organization_words = convert_list_to_lower(organization_words)\n",
        "    person_words = convert_list_to_lower(person_words)\n",
        "    misc_words = convert_list_to_lower(misc_words)\n",
        "\n",
        "    # for calculating the F1-score, we get the true positives, false positives and false negatives\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "\n",
        "    # we construct sets of each particular category, comparing the given labelled words with the predicted/obtained\n",
        "    # The words which are in common denote the true positives\n",
        "    common_words1 = set(loc_words) & set(location_words)\n",
        "    common_words2 = set(org_words) & set(organization_words)\n",
        "    common_words3 = set(per_words) & set(person_words)\n",
        "    common_words4 = set(mis_words) & set(misc_words)\n",
        "    true_positives += len(common_words1)\n",
        "    true_positives += len(common_words2)\n",
        "    true_positives += len(common_words3)\n",
        "    true_positives += len(common_words4)\n",
        "\n",
        "    # Here, un1 will denote the false positives. i.e. the words which were actually present in the given dataset, but not in the predicted outcome\n",
        "    # While un2 willdenote the false negatives, i.e. the words obtained in the predicted outcome but are not actually prsent in the given dataset\n",
        "    un1 = len(loc_words) - len(common_words1) + len(org_words) - len(common_words2) + len(per_words) - len(common_words3) + len(mis_words) - len(common_words4)\n",
        "    un2 = len(location_words) - len(common_words1) + len(organization_words) - len(common_words2) + len(person_words) - len(common_words3) + len(misc_words) - len(common_words4)\n",
        "    false_positives += un1\n",
        "    false_negatives += un2\n",
        "\n",
        "    # Calculating F1 score\n",
        "    if true_positives==0:\n",
        "      precision=0\n",
        "      recall=0\n",
        "    else:\n",
        "      precision = true_positives / (true_positives + false_positives)\n",
        "      recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "    if precision==0 or recall==0:\n",
        "      f1_score=0\n",
        "    else:\n",
        "      f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    # print(\"F1: \", f1_score, \"\\n\")\n",
        "\n",
        "    # We append all results to a csv file, so it cna be easily exported and observed later.\n",
        "    to_be_appended = pd.DataFrame([{'f1_score': f1_score, 'cost': curr_cost, 'output': ans['response'][0]}])\n",
        "    print(to_be_appended)\n",
        "    to_be_appended.to_csv('ans.csv', mode='a', header=False)\n",
        "\n",
        "    # A delay of 20 seconds has to be introduced between each query, as chat-gpt gets rate-limited if more than 3 queries are passed to the API in less than a minute.\n",
        "    time.sleep(20)\n",
        "    # print(\"Delay\")\n",
        "\n",
        "# Here, we try to iterate over the whole given dataset, row by row.\n",
        "for i in range(0, len(df), 3):\n",
        "  batch = df.iloc[i:i+3]\n",
        "  process_batch(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tynf8Rfyp-BZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
